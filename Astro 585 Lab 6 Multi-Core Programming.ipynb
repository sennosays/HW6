{
 "metadata": {
  "language": "Julia",
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Astro 585 Spring 2014<br>\n",
      "Homework 6:  Parallel Computing:  Multi-Core Workstations"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Q1.  First, we'll parallelize some simple code from a previous exercise.  I'll walk you though the syntax in Julia and highlight some potential mistakes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, check how many processors your computer has.  On linux, you can do this by running /cat/cpuinfo from the command line and seeing how many processors are listed.\n",
      "If your machine only has one, then ssh to another computer with Julia installed for the parallel parts.  \n",
      "Next, check how many processor Julia is currently using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nprocs()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When using the REPL interface, you can tell Julia to use multiple cores on a single workstation by starting it like \"julia -p 4\".\n",
      "When using IJulia, it's easier to tell it to add processors from within the notebook with the addprocs(N) command.\n",
      "Using addprocs(N) to tell Julia to use as many processors as your workstation has.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "addprocs(4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "4-element Array{Any,1}:\n",
        " 2\n",
        " 3\n",
        " 4\n",
        " 5"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, check how many processor and how many \"workers\" are active."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "println(\"nprocs()= \",nprocs())\n",
      "println(\"nworkers()= \",nworkers())\n",
      "println(\"myid()= \",myid())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nprocs()= 5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "nworkers()= 4\n",
        "myid()= 1\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1a.  What's the differences between nprocs() and nworkers()?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can instruct Julia to start a calculation on another node using @spawn or @spawnat.  \n",
      "Since the whole point is you want multiple processors working at once, you don't want to have ot wait until that function finished.\n",
      "Therefore, these macros return a RemoteRef data type, rather than the return value.  You can retreive the returned value using fetch."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref = @spawn 1+1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "RemoteRef(3,1,4)"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fetch(ref)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Define our beloved normal pdf function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "normal_pdf (generic function with 1 method)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's write a loop-based integrate function like from the previous lab."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculate \\int_a^b dx func(x) using n function evaluations\n",
      "# Approximates integral as uniformly spaced rectangles\n",
      "# Avoids evaluating func at a or b, in case of singularities\n",
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "int_normal_pdf (generic function with 2 methods)"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's write a function to perform a few tests that our function is accurate"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using Base.Test\n",
      "function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)\n",
      "@time  int_normal_pdf(-1.0,1.0,1000000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "042820328 seconds (135828 bytes allocated)\n",
        "elapsed time: 0.040333057 seconds (64 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.6826896908849539"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's parallelize that loop using the @parallel macro and test the function for accuracy."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "test_int_normal_pdf not defined\nwhile loading In[6], in expression starting on line 11",
       "output_type": "pyerr",
       "traceback": [
        "test_int_normal_pdf not defined\nwhile loading In[6], in expression starting on line 11"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1b.  Notice that we get messages like normal_pdf not defined.  Why is that?  \n",
      "\n",
      "We've defined functions on only the first processor.  We need to make sure they're also definied on any other processors that we want to use the functions.  The easiest way to do that is with the @everywhere macro.  You can either stick it in front of each function (in your notebook) or save the functions to a file and load them with @everywhere include(\"file.jl\").  \n",
      "Let's redefine the above functions, but now forcing them to be declared on each processor."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere normal_pdf(x) = exp(-0.5*x.*x)./sqrt(2.*pi)\n",
      "@everywhere using Base.Test\n",
      "\n",
      "@everywhere function test_int_normal_pdf(func::Function; n::Integer = 1000000, eps::Real = 1.0e-6)\n",
      "  limits = 1:5\n",
      "  for limit in limits\n",
      "    @test_approx_eq_eps func(-limit,limit) erf(limit/sqrt(2.0)) eps\n",
      "  end\n",
      "end\n",
      "\n",
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = 0.\n",
      "  @parallel for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    integral += normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LoadError",
       "evalue": "assertion failed: |func(-limit,limit) - erf(limit / sqrt(2.0))| <= 1.0e-6\n  func(-limit,limit) = 0.0\n  erf(limit / sqrt(2.0)) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[2], in expression starting on line 21",
       "output_type": "pyerr",
       "traceback": [
        "assertion failed: |func(-limit,limit) - erf(limit / sqrt(2.0))| <= 1.0e-6\n  func(-limit,limit) = 0.0\n  erf(limit / sqrt(2.0)) = 0.6826894921370859\n  difference = 0.6826894921370859 > 1.0e-6\nwhile loading In[2], in expression starting on line 21",
        " in error at error.jl:22",
        " in test_approx_eq at test.jl:68",
        " in test_int_normal_pdf at In[2]:7"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1c.  Now, we've eliminated some of the error messages, but our test still fails.  And it can fail badly.  Why is that?\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This type of operation is so common, that Julia provides a special syntax that makes this kind of loop easy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  integral = @parallel (+) for i in 1:n\n",
      "    x = a+i*(b-a)/(n+1)\n",
      "    normal_pdf(x)\n",
      "  end\n",
      "  integral *= (b-a)/n;\n",
      "end\n",
      "\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "064380962 seconds (281204 bytes allocated)\n",
        "elapsed time: 0.048343886 seconds (2352 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "0.6826896908849539"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here Julia is taking the last line of the for loop as the value to be \"reduced\" by the \"+\" operator and the result is stored in integral.  Note that the loop is no longer executed in order, since different processors are executing different parts of the loop."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, let's try performing the same calculation using parallel map function (pmap)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real,b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  dx = (b-a)/n\n",
      "  x = (a+0.5*dx):dx:(b-0.5*dx)\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".259936376 seconds (1261379264 bytes allocated)\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7.2590544 seconds (1261281680 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.6826894921371667"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Yikes, that's crazy slow.  You may even want to restart the kernel.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we'll make use of distributed arrays to demonstrate how to handle more complex parallelization tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(map(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".670989676 seconds (744160888 bytes allocated)\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.621025594 seconds (743964936 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.6826896908849678"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = sum(pmap(normal_pdf,x)) * (b-a)/n \n",
      "end\n",
      "#test_int_normal_pdf(int_normal_pdf)  # Commented out for speed's sake\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 11"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".87996467 seconds (1949439984 bytes allocated)\n",
        "elapsed time: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "11.60687488 seconds (1949246904 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "0.6826896908849678"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "While we succeeded in using distributed array, the performance wasn't very good.  \n",
      "Next, we'll implement a more efficient parallelization using distribute arrays.  \n",
      "For this, you'll need to look up several functions in line 3 below and consider them piece by piece.  \n",
      "First, create a distributed array with dzeros, dones, drand or drandn.  \n",
      "Then, look at which processors are storing data for that array with procs().\n",
      "Then, check how much of the array is stored on the processor running your notebook using localpart() or myindexes()\n",
      "Then, use @spawnat and localpart() to have a processor operate only on the portion of the distributed array that it has in its own memory.\n",
      "Then use fetch with map to retreive the results from each processor working on it's own portion of the distributed array.\n",
      "Finally, use reduce to combine all these elements.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function int_normal_pdf(a::Real, b::Real, n::Integer = 1000000)\n",
      "  @assert(n>2)\n",
      "  x = distribute([ a+i*(b-a)/(n+1) for i in 1:n ])\n",
      "  integral = (b-a)/n * reduce(+,map(fetch,{ (@spawnat p sum(normal_pdf(localpart(x)))) for p in procs(x) }))\n",
      "end\n",
      "test_int_normal_pdf(int_normal_pdf)\n",
      "@time  int_normal_pdf(-1.0,1.0)\n",
      "@time  int_normal_pdf(-1.0,1.0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "elapsed time: 0."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "099670425 seconds (48338180 bytes allocated)\n",
        "elapsed time: 0.063618482 seconds (48010088 bytes allocated)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "0.6826896908849678"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, @parallel is better suited for small loops that execute quickly.\n",
      "Map and pmap are more useful for distributing more time consuming functions.  "
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Q2.  In this exercise, you'll parallelize a more time consuming simulation task.  We'll consider a population of stars, each of which has a  probability $\\eta$ of having one planet.  Then we'll assume a that the planets' orbital periods are drawn from a truncated inverse gamma distribution.  An inverse gamma distribution takes two model parameters, one shape parameter that is like a power-law index for large orbital periods and one scale factor that determines below what period planets will become much less common.  We'll truncate the period distribution, so that no planets orbit inside a star or have a period greater than 4/3 of a year (based on Kepler's mission lifetime).  Each planet has a probability of transiting it's star approximated by $R_*/a$, where $R_*$ is the radius of the star and a is the semi-major axis of the orbit (related to orbital period via Kepler's third law).  (For simplicity, we'll make many assumptions like all stars will be one solar mass and one solar radius, no planet will be too small to be detected above the noise, each star can have only zero or one planets, planets will be on circular orbits, etc. )   We will generate one set of \"observations\" using a particular set of parameter values.  Then we will explore the three-dimensional parameter space ($\\eta$, shape, scale), pretending that we don't know the true values.   For each set of model parameters that we consider, we'll generate one (or more) simulated data sets and comapre those to the \"observations\" via several summary statistics (e.g., number of transiting planets, mean period of transiting planets, standard deviation of transiting planets, etc.) and record a \"distance\" between the summary statistics of the observations and the summary statistics for the simulated data.  You can then plot various projections of this 3-d function to gain intuition for what combinations of $\\eta$, shape and scale are plaussible matches to the data.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2a.  First, read through and load the two files that contain a starter program.\n",
      "Then, perform a set of simulations using parameters similar to those below.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations_once.jl\")  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Cloning cache of ArrayViews from git://github.com/lindahua/ArrayViews.jl.git"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Cloning cache of Distributions from git://github.com/JuliaStats/Distributions.jl.git"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Cloning cache of NumericExtensions from git://github.com/lindahua/NumericExtensions.jl.git"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Cloning cache of PDMats from git://github.com/lindahua/PDMats.jl.git"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Cloning cache of StatsBase from git://github.com/JuliaStats/StatsBase.jl.git"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Installing ArrayViews v0.4.1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Installing Distributions v0.4.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Installing NumericExtensions v0.5.4"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Installing PDMats v0.1.0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Installing StatsBase v0.3.7"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO: Package database updated"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Loading help data...\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@everywhere include(\"HW6_Q2_planet_populations.jl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "min_eta = 0.0\n",
      "max_eta = 1.0\n",
      "min_shape = 0.0001\n",
      "max_shape = 1.0\n",
      "min_log_scale = log10(0.3)\n",
      "max_log_scale = log10(3.0)  \n",
      "num_eta = 4\n",
      "num_shape = 4\n",
      "num_scale = 4\n",
      "num_evals = 1\n",
      "etas = linspace(min_eta,max_eta,num_eta)\n",
      "scales = 10.0.^linspace(min_log_scale,max_log_scale,num_scale)\n",
      "shapes = linspace(min_shape,max_shape,num_shape)\n",
      "num_stars = 16000\n",
      "eta = 0.2\n",
      "shape = 0.1\n",
      "scale = 1.0;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "srand(42)\n",
      "@time result = eval_model_on_grid_loops(etas,shapes,scales,num_stars; num_evals = num_evals, true_eta = eta, true_shape = shape, true_scale = scale);"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that for speed's sake, I've limited the number of function evaluations to only 4 in each of the three model parameters.  \n",
      "Additionally, I've reduced the number of stars to only 16000.  Kepler observed ~160,000 stars at a time.  \n",
      "\n",
      "You might like to plot the results, using a command such as "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "using PyPlot\n",
      "PyPlot.contour(log10(scales),shapes,[minimum(result[:,j,k]) for j in 1:num_scale, k in 1:num_shape])\n",
      "plot(log10([scale]),[shape],\"ro\")  # Put dot where true values of parameters are\n",
      "xlabel(L\"$\\log_{10}(\\mathrm{scale})$\");  ylabel(\"shape\");\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2b.  Parallelize at least one of the for loops to speed up the calculations in eval_model_on_grid_loops.  Test that your code gives similar results for at least a few sets of parameter values. (To save time, you don't need to test every point on the grid).  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2c.  Compare the performance of your parallel code to the serial code while varrying the number of processors (e.g., 1, 2, 4, 8).\n",
      "For your benchmarking, make sure you use a computer that has at least 8 cores.  How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2d.  Modify part of the code, so as to replace the for loops in eval_model_on_grid_map with a call to the map function.  \n",
      "First, test this using a single processor.  Once that works, switch map to pmap and retest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2e.  Compare the performance of your parallel code using map to the parallel code using @parallel.  \n",
      "Again, varry the number of processors (e.g., 1, 2, 4, 8) and make sure you use a computer that has at least 8 cores.  \n",
      "How does the wall clock time scale with the number of processors?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2f.  Modify the code from 2e so as to make use of DistributedArrays.  Retest."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2g. Compare the performance of your parallel code using DistributedArrays to that of your code using standard arrays.  \n",
      "Explain why the performance is does not improve more signiifcantly.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}